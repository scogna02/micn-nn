[
    {
        "label": "Dataset_ETT_hour",
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "isExtraImport": true,
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_minute",
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "isExtraImport": true,
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_Custom",
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "isExtraImport": true,
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_M4",
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "isExtraImport": true,
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "PSMSegLoader",
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "isExtraImport": true,
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "isExtraImport": true,
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "collate_fn",
        "importPath": "data_provider.uea",
        "description": "data_provider.uea",
        "isExtraImport": true,
        "detail": "data_provider.uea",
        "documentation": {}
    },
    {
        "label": "subsample",
        "importPath": "data_provider.uea",
        "description": "data_provider.uea",
        "isExtraImport": true,
        "detail": "data_provider.uea",
        "documentation": {}
    },
    {
        "label": "interpolate_missing",
        "importPath": "data_provider.uea",
        "description": "data_provider.uea",
        "isExtraImport": true,
        "detail": "data_provider.uea",
        "documentation": {}
    },
    {
        "label": "Normalizer",
        "importPath": "data_provider.uea",
        "description": "data_provider.uea",
        "isExtraImport": true,
        "detail": "data_provider.uea",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "time_features",
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "isExtraImport": true,
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "time_features",
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "isExtraImport": true,
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "M4Dataset",
        "importPath": "data_provider.m4",
        "description": "data_provider.m4",
        "isExtraImport": true,
        "detail": "data_provider.m4",
        "documentation": {}
    },
    {
        "label": "M4Meta",
        "importPath": "data_provider.m4",
        "description": "data_provider.m4",
        "isExtraImport": true,
        "detail": "data_provider.m4",
        "documentation": {}
    },
    {
        "label": "load_from_tsfile_to_dataframe",
        "importPath": "sktime.datasets",
        "description": "sktime.datasets",
        "isExtraImport": true,
        "detail": "sktime.datasets",
        "documentation": {}
    },
    {
        "label": "load_from_tsfile_to_dataframe",
        "importPath": "sktime.datasets",
        "description": "sktime.datasets",
        "isExtraImport": true,
        "detail": "sktime.datasets",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "patoolib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "patoolib",
        "description": "patoolib",
        "detail": "patoolib",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "urllib",
        "description": "urllib",
        "isExtraImport": true,
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_hour",
        "importPath": "data_provider2.data_loader",
        "description": "data_provider2.data_loader",
        "isExtraImport": true,
        "detail": "data_provider2.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_minute",
        "importPath": "data_provider2.data_loader",
        "description": "data_provider2.data_loader",
        "isExtraImport": true,
        "detail": "data_provider2.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_Custom",
        "importPath": "data_provider2.data_loader",
        "description": "data_provider2.data_loader",
        "isExtraImport": true,
        "detail": "data_provider2.data_loader",
        "documentation": {}
    },
    {
        "label": "MICN",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "data_provider",
        "importPath": "data_provider2.data_factory",
        "description": "data_provider2.data_factory",
        "isExtraImport": true,
        "detail": "data_provider2.data_factory",
        "documentation": {}
    },
    {
        "label": "data_provider",
        "importPath": "data_provider2.data_factory",
        "description": "data_provider2.data_factory",
        "isExtraImport": true,
        "detail": "data_provider2.data_factory",
        "documentation": {}
    },
    {
        "label": "Exp_Basic",
        "importPath": "exp.exp_basic",
        "description": "exp.exp_basic",
        "isExtraImport": true,
        "detail": "exp.exp_basic",
        "documentation": {}
    },
    {
        "label": "Exp_Basic",
        "importPath": "exp.exp_basic",
        "description": "exp.exp_basic",
        "isExtraImport": true,
        "detail": "exp.exp_basic",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "adjust_learning_rate",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "visual",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "adjust_learning_rate",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "visual",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "metric",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "metric",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "DataEmbedding",
        "importPath": "layers",
        "description": "layers",
        "isExtraImport": true,
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "series_decomp",
        "importPath": "layers",
        "description": "layers",
        "isExtraImport": true,
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "series_decomp_multi",
        "importPath": "layers",
        "description": "layers",
        "isExtraImport": true,
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "offsets",
        "importPath": "pandas.tseries",
        "description": "pandas.tseries",
        "isExtraImport": true,
        "detail": "pandas.tseries",
        "documentation": {}
    },
    {
        "label": "to_offset",
        "importPath": "pandas.tseries.frequencies",
        "description": "pandas.tseries.frequencies",
        "isExtraImport": true,
        "detail": "pandas.tseries.frequencies",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "Exp_Long_Term_Forecast",
        "importPath": "exp.exp_long_term_forecasting",
        "description": "exp.exp_long_term_forecasting",
        "isExtraImport": true,
        "detail": "exp.exp_long_term_forecasting",
        "documentation": {}
    },
    {
        "label": "Exp_Imputation",
        "importPath": "exp.exp_imputation",
        "description": "exp.exp_imputation",
        "isExtraImport": true,
        "detail": "exp.exp_imputation",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.print_args",
        "description": "utils.print_args",
        "isExtraImport": true,
        "detail": "utils.print_args",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "data_provider",
        "kind": 2,
        "importPath": "data_provider.data_factory",
        "description": "data_provider.data_factory",
        "peekOfCode": "def data_provider(args, flag):\n    Data = data_dict[args.data]\n    timeenc = 0 if args.embed != 'timeF' else 1\n    if flag == 'test':\n        shuffle_flag = False\n        drop_last = True\n        batch_size = args.batch_size\n        freq = args.freq\n    else:\n        shuffle_flag = True",
        "detail": "data_provider.data_factory",
        "documentation": {}
    },
    {
        "label": "data_dict",
        "kind": 5,
        "importPath": "data_provider.data_factory",
        "description": "data_provider.data_factory",
        "peekOfCode": "data_dict = {\n    'ETTh1': Dataset_ETT_hour,\n    'ETTh2': Dataset_ETT_hour,\n    'ETTm1': Dataset_ETT_minute,\n    'ETTm2': Dataset_ETT_minute,\n    'custom': Dataset_Custom,\n    'm4': Dataset_M4,\n    'PSM': PSMSegLoader,\n    'MSL': MSLSegLoader,\n    'SMAP': SMAPSegLoader,",
        "detail": "data_provider.data_factory",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_hour",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class Dataset_ETT_hour(Dataset):\n    def __init__(self, root_path, flag='train', size=None,\n                 features='S', data_path='ETTh1.csv',\n                 target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n        # size [seq_len, label_len, pred_len]\n        # info\n        if size == None:\n            self.seq_len = 24 * 4 * 4\n            self.label_len = 24 * 4\n            self.pred_len = 24 * 4",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_minute",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class Dataset_ETT_minute(Dataset):\n    def __init__(self, root_path, flag='train', size=None,\n                 features='S', data_path='ETTm1.csv',\n                 target='OT', scale=True, timeenc=0, freq='t', seasonal_patterns=None):\n        # size [seq_len, label_len, pred_len]\n        # info\n        if size == None:\n            self.seq_len = 24 * 4 * 4\n            self.label_len = 24 * 4\n            self.pred_len = 24 * 4",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_Custom",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class Dataset_Custom(Dataset):\n    def __init__(self, root_path, flag='train', size=None,\n                 features='S', data_path='ETTh1.csv',\n                 target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n        # size [seq_len, label_len, pred_len]\n        # info\n        if size == None:\n            self.seq_len = 24 * 4 * 4\n            self.label_len = 24 * 4\n            self.pred_len = 24 * 4",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_M4",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class Dataset_M4(Dataset):\n    def __init__(self, root_path, flag='pred', size=None,\n                 features='S', data_path='ETTh1.csv',\n                 target='OT', scale=False, inverse=False, timeenc=0, freq='15min',\n                 seasonal_patterns='Yearly'):\n        # size [seq_len, label_len, pred_len]\n        # init\n        self.features = features\n        self.target = target\n        self.scale = scale",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "PSMSegLoader",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class PSMSegLoader(Dataset):\n    def __init__(self, root_path, win_size, step=1, flag=\"train\"):\n        self.flag = flag\n        self.step = step\n        self.win_size = win_size\n        self.scaler = StandardScaler()\n        data = pd.read_csv(os.path.join(root_path, 'train.csv'))\n        data = data.values[:, 1:]\n        data = np.nan_to_num(data)\n        self.scaler.fit(data)",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "MSLSegLoader",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class MSLSegLoader(Dataset):\n    def __init__(self, root_path, win_size, step=1, flag=\"train\"):\n        self.flag = flag\n        self.step = step\n        self.win_size = win_size\n        self.scaler = StandardScaler()\n        data = np.load(os.path.join(root_path, \"MSL_train.npy\"))\n        self.scaler.fit(data)\n        data = self.scaler.transform(data)\n        test_data = np.load(os.path.join(root_path, \"MSL_test.npy\"))",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "SMAPSegLoader",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class SMAPSegLoader(Dataset):\n    def __init__(self, root_path, win_size, step=1, flag=\"train\"):\n        self.flag = flag\n        self.step = step\n        self.win_size = win_size\n        self.scaler = StandardScaler()\n        data = np.load(os.path.join(root_path, \"SMAP_train.npy\"))\n        self.scaler.fit(data)\n        data = self.scaler.transform(data)\n        test_data = np.load(os.path.join(root_path, \"SMAP_test.npy\"))",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "SMDSegLoader",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class SMDSegLoader(Dataset):\n    def __init__(self, root_path, win_size, step=100, flag=\"train\"):\n        self.flag = flag\n        self.step = step\n        self.win_size = win_size\n        self.scaler = StandardScaler()\n        data = np.load(os.path.join(root_path, \"SMD_train.npy\"))\n        self.scaler.fit(data)\n        data = self.scaler.transform(data)\n        test_data = np.load(os.path.join(root_path, \"SMD_test.npy\"))",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "SWATSegLoader",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class SWATSegLoader(Dataset):\n    def __init__(self, root_path, win_size, step=1, flag=\"train\"):\n        self.flag = flag\n        self.step = step\n        self.win_size = win_size\n        self.scaler = StandardScaler()\n        train_data = pd.read_csv(os.path.join(root_path, 'swat_train2.csv'))\n        test_data = pd.read_csv(os.path.join(root_path, 'swat2.csv'))\n        labels = test_data.values[:, -1:]\n        train_data = train_data.values[:, :-1]",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "UEAloader",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class UEAloader(Dataset):\n    \"\"\"\n    Dataset class for datasets included in:\n        Time Series Classification Archive (www.timeseriesclassification.com)\n    Argument:\n        limit_size: float in (0, 1) for debug\n    Attributes:\n        all_df: (num_samples * seq_len, num_columns) dataframe indexed by integer indices, with multiple rows corresponding to the same index (sample).\n            Each row is a time step; Each column contains either metadata (e.g. timestamp) or a feature.\n        feature_df: (num_samples * seq_len, feat_dim) dataframe; contains the subset of columns of `all_df` which correspond to selected features",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "M4Dataset",
        "kind": 6,
        "importPath": "data_provider.m4",
        "description": "data_provider.m4",
        "peekOfCode": "class M4Dataset:\n    ids: np.ndarray\n    groups: np.ndarray\n    frequencies: np.ndarray\n    horizons: np.ndarray\n    values: np.ndarray\n    @staticmethod\n    def load(training: bool = True, dataset_file: str = '../dataset/m4') -> 'M4Dataset':\n        \"\"\"\n        Load cached dataset.",
        "detail": "data_provider.m4",
        "documentation": {}
    },
    {
        "label": "M4Meta",
        "kind": 6,
        "importPath": "data_provider.m4",
        "description": "data_provider.m4",
        "peekOfCode": "class M4Meta:\n    seasonal_patterns = ['Yearly', 'Quarterly', 'Monthly', 'Weekly', 'Daily', 'Hourly']\n    horizons = [6, 8, 18, 13, 14, 48]\n    frequencies = [1, 4, 12, 1, 1, 24]\n    horizons_map = {\n        'Yearly': 6,\n        'Quarterly': 8,\n        'Monthly': 18,\n        'Weekly': 13,\n        'Daily': 14,",
        "detail": "data_provider.m4",
        "documentation": {}
    },
    {
        "label": "url_file_name",
        "kind": 2,
        "importPath": "data_provider.m4",
        "description": "data_provider.m4",
        "peekOfCode": "def url_file_name(url: str) -> str:\n    \"\"\"\n    Extract file name from url.\n    :param url: URL to extract file name from.\n    :return: File name.\n    \"\"\"\n    return url.split('/')[-1] if len(url) > 0 else ''\ndef download(url: str, file_path: str) -> None:\n    \"\"\"\n    Download a file to the given path.",
        "detail": "data_provider.m4",
        "documentation": {}
    },
    {
        "label": "download",
        "kind": 2,
        "importPath": "data_provider.m4",
        "description": "data_provider.m4",
        "peekOfCode": "def download(url: str, file_path: str) -> None:\n    \"\"\"\n    Download a file to the given path.\n    :param url: URL to download\n    :param file_path: Where to download the content.\n    \"\"\"\n    def progress(count, block_size, total_size):\n        progress_pct = float(count * block_size) / float(total_size) * 100.0\n        sys.stdout.write('\\rDownloading {} to {} {:.1f}%'.format(url, file_path, progress_pct))\n        sys.stdout.flush()",
        "detail": "data_provider.m4",
        "documentation": {}
    },
    {
        "label": "load_m4_info",
        "kind": 2,
        "importPath": "data_provider.m4",
        "description": "data_provider.m4",
        "peekOfCode": "def load_m4_info() -> pd.DataFrame:\n    \"\"\"\n    Load M4Info file.\n    :return: Pandas DataFrame of M4Info.\n    \"\"\"\n    return pd.read_csv(INFO_FILE_PATH)",
        "detail": "data_provider.m4",
        "documentation": {}
    },
    {
        "label": "Normalizer",
        "kind": 6,
        "importPath": "data_provider.uea",
        "description": "data_provider.uea",
        "peekOfCode": "class Normalizer(object):\n    \"\"\"\n    Normalizes dataframe across ALL contained rows (time steps). Different from per-sample normalization.\n    \"\"\"\n    def __init__(self, norm_type='standardization', mean=None, std=None, min_val=None, max_val=None):\n        \"\"\"\n        Args:\n            norm_type: choose from:\n                \"standardization\", \"minmax\": normalizes dataframe across ALL contained rows (time steps)\n                \"per_sample_std\", \"per_sample_minmax\": normalizes each sample separately (i.e. across only its own rows)",
        "detail": "data_provider.uea",
        "documentation": {}
    },
    {
        "label": "collate_fn",
        "kind": 2,
        "importPath": "data_provider.uea",
        "description": "data_provider.uea",
        "peekOfCode": "def collate_fn(data, max_len=None):\n    \"\"\"Build mini-batch tensors from a list of (X, mask) tuples. Mask input. Create\n    Args:\n        data: len(batch_size) list of tuples (X, y).\n            - X: torch tensor of shape (seq_length, feat_dim); variable seq_length.\n            - y: torch tensor of shape (num_labels,) : class indices or numerical targets\n                (for classification or regression, respectively). num_labels > 1 for multi-task models\n        max_len: global fixed sequence length. Used for architectures requiring fixed length input,\n            where the batch length cannot vary dynamically. Longer sequences are clipped, shorter are padded with 0s\n    Returns:",
        "detail": "data_provider.uea",
        "documentation": {}
    },
    {
        "label": "padding_mask",
        "kind": 2,
        "importPath": "data_provider.uea",
        "description": "data_provider.uea",
        "peekOfCode": "def padding_mask(lengths, max_len=None):\n    \"\"\"\n    Used to mask padded positions: creates a (batch_size, max_len) boolean mask from a tensor of sequence lengths,\n    where 1 means keep element at this position (time step)\n    \"\"\"\n    batch_size = lengths.numel()\n    max_len = max_len or lengths.max_val()  # trick works because of overloading of 'or' operator for non-boolean types\n    return (torch.arange(0, max_len, device=lengths.device)\n            .type_as(lengths)\n            .repeat(batch_size, 1)",
        "detail": "data_provider.uea",
        "documentation": {}
    },
    {
        "label": "interpolate_missing",
        "kind": 2,
        "importPath": "data_provider.uea",
        "description": "data_provider.uea",
        "peekOfCode": "def interpolate_missing(y):\n    \"\"\"\n    Replaces NaN values in pd.Series `y` using linear interpolation\n    \"\"\"\n    if y.isna().any():\n        y = y.interpolate(method='linear', limit_direction='both')\n    return y\ndef subsample(y, limit=256, factor=2):\n    \"\"\"\n    If a given Series is longer than `limit`, returns subsampled sequence by the specified integer factor",
        "detail": "data_provider.uea",
        "documentation": {}
    },
    {
        "label": "subsample",
        "kind": 2,
        "importPath": "data_provider.uea",
        "description": "data_provider.uea",
        "peekOfCode": "def subsample(y, limit=256, factor=2):\n    \"\"\"\n    If a given Series is longer than `limit`, returns subsampled sequence by the specified integer factor\n    \"\"\"\n    if len(y) > limit:\n        return y[::factor].reset_index(drop=True)\n    return y",
        "detail": "data_provider.uea",
        "documentation": {}
    },
    {
        "label": "data_provider",
        "kind": 2,
        "importPath": "data_provider2.data_factory",
        "description": "data_provider2.data_factory",
        "peekOfCode": "def data_provider(args, flag):\n    Data = data_dict[args.data]\n    timeenc = 0 if args.embed != 'timeF' else 1\n    if flag == 'test':\n        shuffle_flag = False\n        drop_last = True\n        batch_size = 1  # bsz=1 for evaluation\n        freq = args.freq\n    else:\n        shuffle_flag = True",
        "detail": "data_provider2.data_factory",
        "documentation": {}
    },
    {
        "label": "data_dict",
        "kind": 5,
        "importPath": "data_provider2.data_factory",
        "description": "data_provider2.data_factory",
        "peekOfCode": "data_dict = {\n    'ETTh1': Dataset_ETT_hour,\n    'ETTh2': Dataset_ETT_hour,\n    'ETTm1': Dataset_ETT_minute,\n    'ETTm2': Dataset_ETT_minute,\n    'custom': Dataset_Custom\n}\ndef data_provider(args, flag):\n    Data = data_dict[args.data]\n    timeenc = 0 if args.embed != 'timeF' else 1",
        "detail": "data_provider2.data_factory",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_hour",
        "kind": 6,
        "importPath": "data_provider2.data_loader",
        "description": "data_provider2.data_loader",
        "peekOfCode": "class Dataset_ETT_hour(Dataset):\n    def __init__(self, root_path, flag='train', size=None,\n                 features='S', data_path='ETTh1.csv',\n                 target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n        # size [seq_len, label_len, pred_len]\n        # info\n        if size == None:\n            self.seq_len = 24 * 4 * 4\n            self.label_len = 24 * 4\n            self.pred_len = 24 * 4",
        "detail": "data_provider2.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_minute",
        "kind": 6,
        "importPath": "data_provider2.data_loader",
        "description": "data_provider2.data_loader",
        "peekOfCode": "class Dataset_ETT_minute(Dataset):\n    def __init__(self, root_path, flag='train', size=None,\n                 features='S', data_path='ETTm1.csv',\n                 target='OT', scale=True, timeenc=0, freq='t', seasonal_patterns=None):\n        # size [seq_len, label_len, pred_len]\n        # info\n        if size == None:\n            self.seq_len = 24 * 4 * 4\n            self.label_len = 24 * 4\n            self.pred_len = 24 * 4",
        "detail": "data_provider2.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_Custom",
        "kind": 6,
        "importPath": "data_provider2.data_loader",
        "description": "data_provider2.data_loader",
        "peekOfCode": "class Dataset_Custom(Dataset):\n    def __init__(self, root_path, flag='train', size=None,\n                 features='S', data_path='ETTh1.csv',\n                 target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n        # size [seq_len, label_len, pred_len]\n        # info\n        if size == None:\n            self.seq_len = 24 * 4 * 4\n            self.label_len = 24 * 4\n            self.pred_len = 24 * 4",
        "detail": "data_provider2.data_loader",
        "documentation": {}
    },
    {
        "label": "Exp_Basic",
        "kind": 6,
        "importPath": "exp.exp_basic",
        "description": "exp.exp_basic",
        "peekOfCode": "class Exp_Basic(object):\n    def __init__(self, args):\n        self.args = args\n        self.model_dict = {'MICN': MICN,}\n        self.device = self._acquire_device()\n        self.model = self._build_model().to(self.device)\n    def _build_model(self):\n        raise NotImplementedError\n        return None\n    def _acquire_device(self):",
        "detail": "exp.exp_basic",
        "documentation": {}
    },
    {
        "label": "Exp_Imputation",
        "kind": 6,
        "importPath": "exp.exp_imputation",
        "description": "exp.exp_imputation",
        "peekOfCode": "class Exp_Imputation(Exp_Basic):\n    def __init__(self, args):\n        super(Exp_Imputation, self).__init__(args)\n    def _build_model(self):\n        model = self.model_dict[self.args.model].Model(self.args).float()\n        if self.args.use_multi_gpu and self.args.use_gpu:\n            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n        return model\n    def _get_data(self, flag):\n        data_set, data_loader = data_provider(self.args, flag)",
        "detail": "exp.exp_imputation",
        "documentation": {}
    },
    {
        "label": "Exp_Long_Term_Forecast",
        "kind": 6,
        "importPath": "exp.exp_long_term_forecasting",
        "description": "exp.exp_long_term_forecasting",
        "peekOfCode": "class Exp_Long_Term_Forecast(Exp_Basic):\n    def __init__(self, args):\n        super(Exp_Long_Term_Forecast, self).__init__(args)\n    def _build_model(self):\n        model = self.model_dict[self.args.model].Model(self.args).float()\n        if self.args.use_multi_gpu and self.args.use_gpu:\n            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n        return model\n    def _get_data(self, flag):\n        data_set, data_loader = data_provider(self.args, flag)",
        "detail": "exp.exp_long_term_forecasting",
        "documentation": {}
    },
    {
        "label": "MIC",
        "kind": 6,
        "importPath": "models.MICN",
        "description": "models.MICN",
        "peekOfCode": "class MIC(nn.Module):\n    \"\"\"\n    MIC layer to extract local and global features\n    \"\"\"\n    def __init__(self, feature_size=512, n_heads=8, dropout=0.05, decomp_kernel=[32], conv_kernel=[24],\n                 isometric_kernel=[18, 6], device='cuda'):\n        super(MIC, self).__init__()\n        self.conv_kernel = conv_kernel\n        self.device = device\n        # isometric convolution",
        "detail": "models.MICN",
        "documentation": {}
    },
    {
        "label": "SeasonalPrediction",
        "kind": 6,
        "importPath": "models.MICN",
        "description": "models.MICN",
        "peekOfCode": "class SeasonalPrediction(nn.Module):\n    def __init__(self, embedding_size=512, n_heads=8, dropout=0.05, d_layers=1, decomp_kernel=[32], c_out=1,\n                 conv_kernel=[2, 4], isometric_kernel=[18, 6], device='cuda'):\n        super(SeasonalPrediction, self).__init__()\n        self.mic = nn.ModuleList([MIC(feature_size=embedding_size, n_heads=n_heads,\n                                      decomp_kernel=decomp_kernel, conv_kernel=conv_kernel,\n                                      isometric_kernel=isometric_kernel, device=device)\n                                  for i in range(d_layers)])\n        self.projection = nn.Linear(embedding_size, c_out)\n    def forward(self, dec):",
        "detail": "models.MICN",
        "documentation": {}
    },
    {
        "label": "Model",
        "kind": 6,
        "importPath": "models.MICN",
        "description": "models.MICN",
        "peekOfCode": "class Model(nn.Module):\n    \"\"\"\n    Paper link: https://openreview.net/pdf?id=zt53IDUR1U\n    \"\"\"\n    def __init__(self, configs, conv_kernel=[12, 16]):\n        \"\"\"\n        conv_kernel: downsampling and upsampling convolution kernel_size\n        \"\"\"\n        super(Model, self).__init__()\n        # Initialize lists for the kernels of the decomposition operation and isometric convolution",
        "detail": "models.MICN",
        "documentation": {}
    },
    {
        "label": "RSE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def RSE(pred, true):\n    return np.sqrt(np.sum((true - pred) ** 2)) / np.sqrt(np.sum((true - true.mean()) ** 2))\ndef CORR(pred, true):\n    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)\n    d = np.sqrt(((true - true.mean(0)) ** 2 * (pred - pred.mean(0)) ** 2).sum(0))\n    return (u / d).mean(-1)\ndef MAE(pred, true):\n    return np.mean(np.abs(pred - true))\ndef MSE(pred, true):\n    return np.mean((pred - true) ** 2)",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "CORR",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def CORR(pred, true):\n    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)\n    d = np.sqrt(((true - true.mean(0)) ** 2 * (pred - pred.mean(0)) ** 2).sum(0))\n    return (u / d).mean(-1)\ndef MAE(pred, true):\n    return np.mean(np.abs(pred - true))\ndef MSE(pred, true):\n    return np.mean((pred - true) ** 2)\ndef RMSE(pred, true):\n    return np.sqrt(MSE(pred, true))",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "MAE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def MAE(pred, true):\n    return np.mean(np.abs(pred - true))\ndef MSE(pred, true):\n    return np.mean((pred - true) ** 2)\ndef RMSE(pred, true):\n    return np.sqrt(MSE(pred, true))\ndef MAPE(pred, true):\n    return np.mean(np.abs((pred - true) / true))\ndef MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "MSE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def MSE(pred, true):\n    return np.mean((pred - true) ** 2)\ndef RMSE(pred, true):\n    return np.sqrt(MSE(pred, true))\ndef MAPE(pred, true):\n    return np.mean(np.abs((pred - true) / true))\ndef MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))\ndef metric(pred, true):\n    mae = MAE(pred, true)",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "RMSE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def RMSE(pred, true):\n    return np.sqrt(MSE(pred, true))\ndef MAPE(pred, true):\n    return np.mean(np.abs((pred - true) / true))\ndef MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))\ndef metric(pred, true):\n    mae = MAE(pred, true)\n    mse = MSE(pred, true)\n    rmse = RMSE(pred, true)",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "MAPE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def MAPE(pred, true):\n    return np.mean(np.abs((pred - true) / true))\ndef MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))\ndef metric(pred, true):\n    mae = MAE(pred, true)\n    mse = MSE(pred, true)\n    rmse = RMSE(pred, true)\n    mape = MAPE(pred, true)\n    mspe = MSPE(pred, true)",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "MSPE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))\ndef metric(pred, true):\n    mae = MAE(pred, true)\n    mse = MSE(pred, true)\n    rmse = RMSE(pred, true)\n    mape = MAPE(pred, true)\n    mspe = MSPE(pred, true)\n    return mae, mse, rmse, mape, mspe",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "metric",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def metric(pred, true):\n    mae = MAE(pred, true)\n    mse = MSE(pred, true)\n    rmse = RMSE(pred, true)\n    mape = MAPE(pred, true)\n    mspe = MSPE(pred, true)\n    return mae, mse, rmse, mape, mspe",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "print_args",
        "kind": 2,
        "importPath": "utils.print_args",
        "description": "utils.print_args",
        "peekOfCode": "def print_args(args):\n    print(\"\\033[1m\" + \"Basic Config\" + \"\\033[0m\")\n    print(f'  {\"Task Name:\":<20}{args.task_name:<20}{\"Is Training:\":<20}{args.is_training:<20}')\n    print(f'  {\"Model ID:\":<20}{args.model_id:<20}{\"Model:\":<20}{args.model:<20}')\n    print()\n    print(\"\\033[1m\" + \"Data Loader\" + \"\\033[0m\")\n    print(f'  {\"Data:\":<20}{args.data:<20}{\"Root Path:\":<20}{args.root_path:<20}')\n    print(f'  {\"Data Path:\":<20}{args.data_path:<20}{\"Features:\":<20}{args.features:<20}')\n    print(f'  {\"Target:\":<20}{args.target:<20}{\"Freq:\":<20}{args.freq:<20}')\n    print(f'  {\"Checkpoints:\":<20}{args.checkpoints:<20}')",
        "detail": "utils.print_args",
        "documentation": {}
    },
    {
        "label": "TimeFeature",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class TimeFeature:\n    def __init__(self):\n        pass\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        pass\n    def __repr__(self):\n        return self.__class__.__name__ + \"()\"\nclass SecondOfMinute(TimeFeature):\n    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "SecondOfMinute",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class SecondOfMinute(TimeFeature):\n    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.second / 59.0 - 0.5\nclass MinuteOfHour(TimeFeature):\n    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.minute / 59.0 - 0.5\nclass HourOfDay(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "MinuteOfHour",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class MinuteOfHour(TimeFeature):\n    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.minute / 59.0 - 0.5\nclass HourOfDay(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.hour / 23.0 - 0.5\nclass DayOfWeek(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "HourOfDay",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class HourOfDay(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.hour / 23.0 - 0.5\nclass DayOfWeek(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.dayofweek / 6.0 - 0.5\nclass DayOfMonth(TimeFeature):\n    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "DayOfWeek",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class DayOfWeek(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.dayofweek / 6.0 - 0.5\nclass DayOfMonth(TimeFeature):\n    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.day - 1) / 30.0 - 0.5\nclass DayOfYear(TimeFeature):\n    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "DayOfMonth",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class DayOfMonth(TimeFeature):\n    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.day - 1) / 30.0 - 0.5\nclass DayOfYear(TimeFeature):\n    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.dayofyear - 1) / 365.0 - 0.5\nclass MonthOfYear(TimeFeature):\n    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "DayOfYear",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class DayOfYear(TimeFeature):\n    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.dayofyear - 1) / 365.0 - 0.5\nclass MonthOfYear(TimeFeature):\n    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.month - 1) / 11.0 - 0.5\nclass WeekOfYear(TimeFeature):\n    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "MonthOfYear",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class MonthOfYear(TimeFeature):\n    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.month - 1) / 11.0 - 0.5\nclass WeekOfYear(TimeFeature):\n    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.isocalendar().week - 1) / 52.0 - 0.5\ndef time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n    \"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "WeekOfYear",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class WeekOfYear(TimeFeature):\n    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.isocalendar().week - 1) / 52.0 - 0.5\ndef time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n    \"\"\"\n    Returns a list of time features that will be appropriate for the given frequency string.\n    Parameters\n    ----------\n    freq_str",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "time_features_from_frequency_str",
        "kind": 2,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n    \"\"\"\n    Returns a list of time features that will be appropriate for the given frequency string.\n    Parameters\n    ----------\n    freq_str\n        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n    \"\"\"\n    features_by_offsets = {\n        offsets.YearEnd: [],",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "time_features",
        "kind": 2,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "def time_features(dates, freq='h'):\n    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "kind": 6,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "class EarlyStopping:\n    def __init__(self, patience=7, verbose=False, delta=0):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n    def __call__(self, val_loss, model, path):",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "dotdict",
        "kind": 6,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "class dotdict(dict):\n    \"\"\"dot.notation access to dictionary attributes\"\"\"\n    __getattr__ = dict.get\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\nclass StandardScaler():\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n    def transform(self, data):",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "kind": 6,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "class StandardScaler():\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n    def transform(self, data):\n        return (data - self.mean) / self.std\n    def inverse_transform(self, data):\n        return (data * self.std) + self.mean\ndef visual(true, preds=None, name='./pic/test.pdf'):\n    \"\"\"",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "adjust_learning_rate",
        "kind": 2,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "def adjust_learning_rate(optimizer, epoch, args):\n    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n    if args.lradj == 'type1':\n        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n    elif args.lradj == 'type2':\n        lr_adjust = {\n            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n            10: 5e-7, 15: 1e-7, 20: 5e-8\n        }\n    elif args.lradj == \"cosine\":",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "visual",
        "kind": 2,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "def visual(true, preds=None, name='./pic/test.pdf'):\n    \"\"\"\n    Results visualization\n    \"\"\"\n    plt.figure()\n    plt.plot(true, label='GroundTruth', linewidth=2)\n    if preds is not None:\n        plt.plot(preds, label='Prediction', linewidth=2)\n    plt.legend()\n    plt.savefig(name, bbox_inches='tight')",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "adjustment",
        "kind": 2,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "def adjustment(gt, pred):\n    anomaly_state = False\n    for i in range(len(gt)):\n        if gt[i] == 1 and pred[i] == 1 and not anomaly_state:\n            anomaly_state = True\n            for j in range(i, 0, -1):\n                if gt[j] == 0:\n                    break\n                else:\n                    if pred[j] == 0:",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "cal_accuracy",
        "kind": 2,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "def cal_accuracy(y_pred, y_true):\n    return np.mean(y_pred == y_true)",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "PositionalEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class PositionalEmbedding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEmbedding, self).__init__()\n        # Compute the positional encodings once in log space.\n        pe = torch.zeros(max_len, d_model).float()\n        pe.require_grad = False\n        position = torch.arange(0, max_len).float().unsqueeze(1)\n        div_term = (torch.arange(0, d_model, 2).float()\n                    * -(math.log(10000.0) / d_model)).exp()\n        pe[:, 0::2] = torch.sin(position * div_term)",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "TokenEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class TokenEmbedding(nn.Module):\n    def __init__(self, c_in, d_model):\n        super(TokenEmbedding, self).__init__()\n        padding = 1 if torch.__version__ >= '1.5.0' else 2\n        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n        for m in self.modules():\n            if isinstance(m, nn.Conv1d):\n                nn.init.kaiming_normal_(\n                    m.weight, mode='fan_in', nonlinearity='leaky_relu')",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "FixedEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class FixedEmbedding(nn.Module):\n    def __init__(self, c_in, d_model):\n        super(FixedEmbedding, self).__init__()\n        w = torch.zeros(c_in, d_model).float()\n        w.require_grad = False\n        position = torch.arange(0, c_in).float().unsqueeze(1)\n        div_term = (torch.arange(0, d_model, 2).float()\n                    * -(math.log(10000.0) / d_model)).exp()\n        w[:, 0::2] = torch.sin(position * div_term)\n        w[:, 1::2] = torch.cos(position * div_term)",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "TemporalEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class TemporalEmbedding(nn.Module):\n    def __init__(self, d_model, embed_type='fixed', freq='h'):\n        super(TemporalEmbedding, self).__init__()\n        minute_size = 4\n        hour_size = 24\n        weekday_size = 7\n        day_size = 32\n        month_size = 13\n        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n        if freq == 't':",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "TimeFeatureEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class TimeFeatureEmbedding(nn.Module):\n    def __init__(self, d_model, embed_type='timeF', freq='h'):\n        super(TimeFeatureEmbedding, self).__init__()\n        freq_map = {'h': 4, 't': 5, 's': 6,\n                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n        d_inp = freq_map[freq]\n        self.embed = nn.Linear(d_inp, d_model, bias=False)\n    def forward(self, x):\n        return self.embed(x)\nclass DataEmbedding(nn.Module):",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "DataEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class DataEmbedding(nn.Module):\n    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n        super(DataEmbedding, self).__init__()\n        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n        self.position_embedding = PositionalEmbedding(d_model=d_model)\n        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n            d_model=d_model, embed_type=embed_type, freq=freq)\n        self.dropout = nn.Dropout(p=dropout)\n    def forward(self, x, x_mark):",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "moving_avg",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class moving_avg(nn.Module):\n    \"\"\"\n    Moving average block to highlight the trend of time series\n    \"\"\"\n    def __init__(self, kernel_size, stride):\n        super(moving_avg, self).__init__()\n        self.kernel_size = kernel_size\n        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n    def forward(self, x):\n        # padding on the both ends of time series",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "series_decomp",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class series_decomp(nn.Module):\n    \"\"\"\n    Series decomposition block\n    \"\"\"\n    def __init__(self, kernel_size):\n        super(series_decomp, self).__init__()\n        self.moving_avg = moving_avg(kernel_size, stride=1)\n    def forward(self, x):\n        moving_mean = self.moving_avg(x)\n        res = x - moving_mean",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "series_decomp_multi",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class series_decomp_multi(nn.Module):\n    \"\"\"\n    Multiple Series decomposition block from FEDformer\n    \"\"\"\n    def __init__(self, kernel_size):\n        super(series_decomp_multi, self).__init__()\n        self.kernel_size = kernel_size\n        self.series_decomp = [series_decomp(kernel) for kernel in kernel_size]\n    def forward(self, x):\n        moving_mean = []",
        "detail": "layers",
        "documentation": {}
    }
]