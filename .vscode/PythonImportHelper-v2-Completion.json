[
    {
        "label": "Dataset_Weather",
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "isExtraImport": true,
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_hour",
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "isExtraImport": true,
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_minute",
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "isExtraImport": true,
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "time_features",
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "isExtraImport": true,
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "data_provider",
        "importPath": "data_provider.data_factory",
        "description": "data_provider.data_factory",
        "isExtraImport": true,
        "detail": "data_provider.data_factory",
        "documentation": {}
    },
    {
        "label": "data_provider",
        "importPath": "data_provider.data_factory",
        "description": "data_provider.data_factory",
        "isExtraImport": true,
        "detail": "data_provider.data_factory",
        "documentation": {}
    },
    {
        "label": "data_provider",
        "importPath": "data_provider.data_factory",
        "description": "data_provider.data_factory",
        "isExtraImport": true,
        "detail": "data_provider.data_factory",
        "documentation": {}
    },
    {
        "label": "Exp_Basic",
        "importPath": "exp.exp_basic",
        "description": "exp.exp_basic",
        "isExtraImport": true,
        "detail": "exp.exp_basic",
        "documentation": {}
    },
    {
        "label": "Exp_Basic",
        "importPath": "exp.exp_basic",
        "description": "exp.exp_basic",
        "isExtraImport": true,
        "detail": "exp.exp_basic",
        "documentation": {}
    },
    {
        "label": "Exp_Basic",
        "importPath": "exp.exp_basic",
        "description": "exp.exp_basic",
        "isExtraImport": true,
        "detail": "exp.exp_basic",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "adjust_learning_rate",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "visual",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "adjust_learning_rate",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "visual",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "adjust_learning_rate",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "visual",
        "importPath": "utils.tools",
        "description": "utils.tools",
        "isExtraImport": true,
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "metric",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "metric",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "metric",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "array",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "zeros",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "full",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "argmin",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "inf",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "ndim",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "MICN",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "MICN",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "MICN",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "DataEmbedding",
        "importPath": "layers",
        "description": "layers",
        "isExtraImport": true,
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "series_decomp",
        "importPath": "layers",
        "description": "layers",
        "isExtraImport": true,
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "series_decomp_multi",
        "importPath": "layers",
        "description": "layers",
        "isExtraImport": true,
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "isinf",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "cdist",
        "importPath": "scipy.spatial.distance",
        "description": "scipy.spatial.distance",
        "isExtraImport": true,
        "detail": "scipy.spatial.distance",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "offsets",
        "importPath": "pandas.tseries",
        "description": "pandas.tseries",
        "isExtraImport": true,
        "detail": "pandas.tseries",
        "documentation": {}
    },
    {
        "label": "to_offset",
        "importPath": "pandas.tseries.frequencies",
        "description": "pandas.tseries.frequencies",
        "isExtraImport": true,
        "detail": "pandas.tseries.frequencies",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "Exp_Long_Term_Forecast",
        "importPath": "exp.exp",
        "description": "exp.exp",
        "isExtraImport": true,
        "detail": "exp.exp",
        "documentation": {}
    },
    {
        "label": "Exp_Imputation",
        "importPath": "exp.exp",
        "description": "exp.exp",
        "isExtraImport": true,
        "detail": "exp.exp",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "utils.print_args",
        "description": "utils.print_args",
        "isExtraImport": true,
        "detail": "utils.print_args",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "data_provider",
        "kind": 2,
        "importPath": "data_provider.data_factory",
        "description": "data_provider.data_factory",
        "peekOfCode": "def data_provider(args, flag):\n    Data = data_dict[args.data]\n    timeenc = 0 if args.embed != 'timeF' else 1\n    if flag == 'test':\n        shuffle_flag = False\n        drop_last = True\n        batch_size = args.batch_size\n        freq = args.freq\n    else:\n        shuffle_flag = True",
        "detail": "data_provider.data_factory",
        "documentation": {}
    },
    {
        "label": "data_dict",
        "kind": 5,
        "importPath": "data_provider.data_factory",
        "description": "data_provider.data_factory",
        "peekOfCode": "data_dict = {\n    'ETTh1': Dataset_ETT_hour,\n    'ETTh2': Dataset_ETT_hour,\n    'ETTm1': Dataset_ETT_minute,\n    'ETTm2': Dataset_ETT_minute,\n    'custom': Dataset_Weather\n}\ndef data_provider(args, flag):\n    Data = data_dict[args.data]\n    timeenc = 0 if args.embed != 'timeF' else 1",
        "detail": "data_provider.data_factory",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_hour",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class Dataset_ETT_hour(Dataset):\n    def __init__(self, args, root_path, flag='train', size=None,\n                 features='S', data_path='ETTh1.csv',\n                 target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n        # size [seq_len, label_len, pred_len]\n        self.args = args\n        # info\n        if size == None:\n            self.seq_len = 24 * 4 * 4\n            self.label_len = 24 * 4",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_ETT_minute",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class Dataset_ETT_minute(Dataset):\n    def __init__(self, args, root_path, flag='train', size=None,\n                 features='S', data_path='ETTm1.csv',\n                 target='OT', scale=True, timeenc=0, freq='t', seasonal_patterns=None):\n        # size [seq_len, label_len, pred_len]\n        self.args = args\n        # info\n        if size == None:\n            self.seq_len = 24 * 4 * 4\n            self.label_len = 24 * 4",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Dataset_Weather",
        "kind": 6,
        "importPath": "data_provider.data_loader",
        "description": "data_provider.data_loader",
        "peekOfCode": "class Dataset_Weather(Dataset):\n    def __init__(self,\n                 args,\n                 root_path,\n                 data_path,\n                 size,\n                 features,\n                 flag,\n                 target,\n                 scale=True,",
        "detail": "data_provider.data_loader",
        "documentation": {}
    },
    {
        "label": "Exp_Basic",
        "kind": 6,
        "importPath": "exp.exp",
        "description": "exp.exp",
        "peekOfCode": "class Exp_Basic(object):\n    def __init__(self, args):\n        self.args = args\n        self.model_dict = {'MICN': MICN,}\n        self.device = self._acquire_device()\n        self.model = self._build_model().to(self.device)\n    def _build_model(self):\n        raise NotImplementedError\n        return None\n    def _acquire_device(self):",
        "detail": "exp.exp",
        "documentation": {}
    },
    {
        "label": "Exp_Imputation",
        "kind": 6,
        "importPath": "exp.exp",
        "description": "exp.exp",
        "peekOfCode": "class Exp_Imputation(Exp_Basic):\n    def __init__(self, args):\n        super(Exp_Imputation, self).__init__(args)\n    def _build_model(self):\n        model = self.model_dict[self.args.model].Model(self.args).float()\n        if self.args.use_multi_gpu and self.args.use_gpu:\n            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n        return model\n    def _get_data(self, flag):\n        data_set, data_loader = data_provider(self.args, flag)",
        "detail": "exp.exp",
        "documentation": {}
    },
    {
        "label": "Exp_Long_Term_Forecast",
        "kind": 6,
        "importPath": "exp.exp",
        "description": "exp.exp",
        "peekOfCode": "class Exp_Long_Term_Forecast(Exp_Basic):\n    def __init__(self, args):\n        super(Exp_Long_Term_Forecast, self).__init__(args)\n    def _build_model(self):\n        model = self.model_dict[self.args.model].Model(self.args).float()\n        if self.args.use_multi_gpu and self.args.use_gpu:\n            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n        return model\n    def _get_data(self, flag):\n        data_set, data_loader = data_provider(self.args, flag)",
        "detail": "exp.exp",
        "documentation": {}
    },
    {
        "label": "Exp_Basic",
        "kind": 6,
        "importPath": "exp.exp_basic",
        "description": "exp.exp_basic",
        "peekOfCode": "class Exp_Basic(object):\n    def __init__(self, args):\n        self.args = args\n        self.model_dict = {'MICN': MICN,}\n        self.device = self._acquire_device()\n        self.model = self._build_model().to(self.device)\n    def _build_model(self):\n        raise NotImplementedError\n        return None\n    def _acquire_device(self):",
        "detail": "exp.exp_basic",
        "documentation": {}
    },
    {
        "label": "Exp_Imputation",
        "kind": 6,
        "importPath": "exp.exp_imputation",
        "description": "exp.exp_imputation",
        "peekOfCode": "class Exp_Imputation(Exp_Basic):\n    def __init__(self, args):\n        super(Exp_Imputation, self).__init__(args)\n    def _build_model(self):\n        model = self.model_dict[self.args.model].Model(self.args).float()\n        if self.args.use_multi_gpu and self.args.use_gpu:\n            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n        return model\n    def _get_data(self, flag):\n        data_set, data_loader = data_provider(self.args, flag)",
        "detail": "exp.exp_imputation",
        "documentation": {}
    },
    {
        "label": "Exp_Basic",
        "kind": 6,
        "importPath": "exp.exp_long_term_forecasting",
        "description": "exp.exp_long_term_forecasting",
        "peekOfCode": "class Exp_Basic(object):\n    def __init__(self, args):\n        self.args = args\n        self.model_dict = {'MICN': MICN,}\n        self.device = self._acquire_device()\n        self.model = self._build_model().to(self.device)\n    def _build_model(self):\n        raise NotImplementedError\n        return None\n    def _acquire_device(self):",
        "detail": "exp.exp_long_term_forecasting",
        "documentation": {}
    },
    {
        "label": "Exp_Imputation",
        "kind": 6,
        "importPath": "exp.exp_long_term_forecasting",
        "description": "exp.exp_long_term_forecasting",
        "peekOfCode": "class Exp_Imputation(Exp_Basic):\n    def __init__(self, args):\n        super(Exp_Imputation, self).__init__(args)\n    def _build_model(self):\n        model = self.model_dict[self.args.model].Model(self.args).float()\n        if self.args.use_multi_gpu and self.args.use_gpu:\n            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n        return model\n    def _get_data(self, flag):\n        data_set, data_loader = data_provider(self.args, flag)",
        "detail": "exp.exp_long_term_forecasting",
        "documentation": {}
    },
    {
        "label": "Exp_Long_Term_Forecast",
        "kind": 6,
        "importPath": "exp.exp_long_term_forecasting",
        "description": "exp.exp_long_term_forecasting",
        "peekOfCode": "class Exp_Long_Term_Forecast(Exp_Basic):\n    def __init__(self, args):\n        super(Exp_Long_Term_Forecast, self).__init__(args)\n    def _build_model(self):\n        model = self.model_dict[self.args.model].Model(self.args).float()\n        if self.args.use_multi_gpu and self.args.use_gpu:\n            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n        return model\n    def _get_data(self, flag):\n        data_set, data_loader = data_provider(self.args, flag)",
        "detail": "exp.exp_long_term_forecasting",
        "documentation": {}
    },
    {
        "label": "MIC",
        "kind": 6,
        "importPath": "models.MICN",
        "description": "models.MICN",
        "peekOfCode": "class MIC(nn.Module):\n    \"\"\"\n    MIC layer to extract local and global features\n    \"\"\"\n    def __init__(self, feature_size=512, n_heads=8, dropout=0.05, decomp_kernel=[32], conv_kernel=[24],\n                 isometric_kernel=[18, 6], device='cuda'):\n        super(MIC, self).__init__()\n        self.conv_kernel = conv_kernel\n        self.device = device\n        # isometric convolution",
        "detail": "models.MICN",
        "documentation": {}
    },
    {
        "label": "SeasonalPrediction",
        "kind": 6,
        "importPath": "models.MICN",
        "description": "models.MICN",
        "peekOfCode": "class SeasonalPrediction(nn.Module):\n    def __init__(self, embedding_size=512, n_heads=8, dropout=0.05, d_layers=1, decomp_kernel=[32], c_out=1,\n                 conv_kernel=[2, 4], isometric_kernel=[18, 6], device='cuda'):\n        super(SeasonalPrediction, self).__init__()\n        self.mic = nn.ModuleList([MIC(feature_size=embedding_size, n_heads=n_heads,\n                                      decomp_kernel=decomp_kernel, conv_kernel=conv_kernel,\n                                      isometric_kernel=isometric_kernel, device=device)\n                                  for i in range(d_layers)])\n        self.projection = nn.Linear(embedding_size, c_out)\n    def forward(self, dec):",
        "detail": "models.MICN",
        "documentation": {}
    },
    {
        "label": "Model",
        "kind": 6,
        "importPath": "models.MICN",
        "description": "models.MICN",
        "peekOfCode": "class Model(nn.Module):\n    \"\"\"\n    Paper link: https://openreview.net/pdf?id=zt53IDUR1U\n    \"\"\"\n    def __init__(self, configs, conv_kernel=[12, 16]):\n        \"\"\"\n        conv_kernel: downsampling and upsampling convolution kernel_size\n        \"\"\"\n        super(Model, self).__init__()\n        # Initialize lists for the kernels of the decomposition operation and isometric convolution",
        "detail": "models.MICN",
        "documentation": {}
    },
    {
        "label": "calculate_ADF",
        "kind": 2,
        "importPath": "utils.ADFtest",
        "description": "utils.ADFtest",
        "peekOfCode": "def calculate_ADF(root_path,data_path):\n    df_raw = pd.read_csv(os.path.join(root_path,data_path))\n    cols = list(df_raw.columns)\n    cols.remove('date')\n    df_raw = df_raw[cols]\n    adf_list = []\n    for i in cols:\n        df_data = df_raw[i]\n        adf = adfuller(df_data, maxlag = 1)\n        print(adf)",
        "detail": "utils.ADFtest",
        "documentation": {}
    },
    {
        "label": "calculate_target_ADF",
        "kind": 2,
        "importPath": "utils.ADFtest",
        "description": "utils.ADFtest",
        "peekOfCode": "def calculate_target_ADF(root_path,data_path,target='OT'):\n    df_raw = pd.read_csv(os.path.join(root_path,data_path))\n    target_cols = target.split(',')\n    # df_data = df_raw[target]\n    df_raw = df_raw[target_cols]\n    adf_list = []\n    for i in target_cols:\n        df_data = df_raw[i]\n        adf = adfuller(df_data, maxlag = 1)\n        # print(adf)",
        "detail": "utils.ADFtest",
        "documentation": {}
    },
    {
        "label": "archADF",
        "kind": 2,
        "importPath": "utils.ADFtest",
        "description": "utils.ADFtest",
        "peekOfCode": "def archADF(root_path, data_path):\n    df = pd.read_csv(os.path.join(root_path,data_path))\n    cols = df.columns[1:]\n    stats = 0\n    for target_col in cols:\n        series = df[target_col].values\n        adf = ADF(series)\n        stat = adf.stat\n        stats += stat\n    return stats/len(cols)",
        "detail": "utils.ADFtest",
        "documentation": {}
    },
    {
        "label": "jitter",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def jitter(x, sigma=0.03):\n    # https://arxiv.org/pdf/1706.00527.pdf\n    return x + np.random.normal(loc=0., scale=sigma, size=x.shape)\ndef scaling(x, sigma=0.1):\n    # https://arxiv.org/pdf/1706.00527.pdf\n    factor = np.random.normal(loc=1., scale=sigma, size=(x.shape[0],x.shape[2]))\n    return np.multiply(x, factor[:,np.newaxis,:])\ndef rotation(x):\n    x = np.array(x)\n    flip = np.random.choice([-1, 1], size=(x.shape[0],x.shape[2]))",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "scaling",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def scaling(x, sigma=0.1):\n    # https://arxiv.org/pdf/1706.00527.pdf\n    factor = np.random.normal(loc=1., scale=sigma, size=(x.shape[0],x.shape[2]))\n    return np.multiply(x, factor[:,np.newaxis,:])\ndef rotation(x):\n    x = np.array(x)\n    flip = np.random.choice([-1, 1], size=(x.shape[0],x.shape[2]))\n    rotate_axis = np.arange(x.shape[2])\n    np.random.shuffle(rotate_axis)\n    return flip[:,np.newaxis,:] * x[:,:,rotate_axis]",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "rotation",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def rotation(x):\n    x = np.array(x)\n    flip = np.random.choice([-1, 1], size=(x.shape[0],x.shape[2]))\n    rotate_axis = np.arange(x.shape[2])\n    np.random.shuffle(rotate_axis)\n    return flip[:,np.newaxis,:] * x[:,:,rotate_axis]\ndef permutation(x, max_segments=5, seg_mode=\"equal\"):\n    orig_steps = np.arange(x.shape[1])\n    num_segs = np.random.randint(1, max_segments, size=(x.shape[0]))\n    ret = np.zeros_like(x)",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "permutation",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def permutation(x, max_segments=5, seg_mode=\"equal\"):\n    orig_steps = np.arange(x.shape[1])\n    num_segs = np.random.randint(1, max_segments, size=(x.shape[0]))\n    ret = np.zeros_like(x)\n    for i, pat in enumerate(x):\n        if num_segs[i] > 1:\n            if seg_mode == \"random\":\n                split_points = np.random.choice(x.shape[1]-2, num_segs[i]-1, replace=False)\n                split_points.sort()\n                splits = np.split(orig_steps, split_points)",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "magnitude_warp",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def magnitude_warp(x, sigma=0.2, knot=4):\n    from scipy.interpolate import CubicSpline\n    orig_steps = np.arange(x.shape[1])\n    random_warps = np.random.normal(loc=1.0, scale=sigma, size=(x.shape[0], knot+2, x.shape[2]))\n    warp_steps = (np.ones((x.shape[2],1))*(np.linspace(0, x.shape[1]-1., num=knot+2))).T\n    ret = np.zeros_like(x)\n    for i, pat in enumerate(x):\n        warper = np.array([CubicSpline(warp_steps[:,dim], random_warps[i,:,dim])(orig_steps) for dim in range(x.shape[2])]).T\n        ret[i] = pat * warper\n    return ret",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "time_warp",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def time_warp(x, sigma=0.2, knot=4):\n    from scipy.interpolate import CubicSpline\n    orig_steps = np.arange(x.shape[1])\n    random_warps = np.random.normal(loc=1.0, scale=sigma, size=(x.shape[0], knot+2, x.shape[2]))\n    warp_steps = (np.ones((x.shape[2],1))*(np.linspace(0, x.shape[1]-1., num=knot+2))).T\n    ret = np.zeros_like(x)\n    for i, pat in enumerate(x):\n        for dim in range(x.shape[2]):\n            time_warp = CubicSpline(warp_steps[:,dim], warp_steps[:,dim] * random_warps[i,:,dim])(orig_steps)\n            scale = (x.shape[1]-1)/time_warp[-1]",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "window_slice",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def window_slice(x, reduce_ratio=0.9):\n    # https://halshs.archives-ouvertes.fr/halshs-01357973/document\n    target_len = np.ceil(reduce_ratio*x.shape[1]).astype(int)\n    if target_len >= x.shape[1]:\n        return x\n    starts = np.random.randint(low=0, high=x.shape[1]-target_len, size=(x.shape[0])).astype(int)\n    ends = (target_len + starts).astype(int)\n    ret = np.zeros_like(x)\n    for i, pat in enumerate(x):\n        for dim in range(x.shape[2]):",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "window_warp",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def window_warp(x, window_ratio=0.1, scales=[0.5, 2.]):\n    # https://halshs.archives-ouvertes.fr/halshs-01357973/document\n    warp_scales = np.random.choice(scales, x.shape[0])\n    warp_size = np.ceil(window_ratio*x.shape[1]).astype(int)\n    window_steps = np.arange(warp_size)\n    window_starts = np.random.randint(low=1, high=x.shape[1]-warp_size-1, size=(x.shape[0])).astype(int)\n    window_ends = (window_starts + warp_size).astype(int)\n    ret = np.zeros_like(x)\n    for i, pat in enumerate(x):\n        for dim in range(x.shape[2]):",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "spawner",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def spawner(x, labels, sigma=0.05, verbose=0):\n    # https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6983028/\n    # use verbose=-1 to turn off warnings\n    # use verbose=1 to print out figures\n    import utils.dtw as dtw\n    random_points = np.random.randint(low=1, high=x.shape[1]-1, size=x.shape[0])\n    window = np.ceil(x.shape[1] / 10.).astype(int)\n    orig_steps = np.arange(x.shape[1])\n    l = np.argmax(labels, axis=1) if labels.ndim > 1 else labels\n    ret = np.zeros_like(x)",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "wdba",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def wdba(x, labels, batch_size=6, slope_constraint=\"symmetric\", use_window=True, verbose=0):\n    # https://ieeexplore.ieee.org/document/8215569\n    # use verbose = -1 to turn off warnings    \n    # slope_constraint is for DTW. \"symmetric\" or \"asymmetric\"\n    x = np.array(x)\n    import utils.dtw as dtw\n    if use_window:\n        window = np.ceil(x.shape[1] / 10.).astype(int)\n    else:\n        window = None",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "random_guided_warp",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def random_guided_warp(x, labels, slope_constraint=\"symmetric\", use_window=True, dtw_type=\"normal\", verbose=0):\n    # use verbose = -1 to turn off warnings\n    # slope_constraint is for DTW. \"symmetric\" or \"asymmetric\"\n    # dtw_type is for shapeDTW or DTW. \"normal\" or \"shape\"\n    import utils.dtw as dtw\n    if use_window:\n        window = np.ceil(x.shape[1] / 10.).astype(int)\n    else:\n        window = None\n    orig_steps = np.arange(x.shape[1])",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "random_guided_warp_shape",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def random_guided_warp_shape(x, labels, slope_constraint=\"symmetric\", use_window=True):\n    return random_guided_warp(x, labels, slope_constraint, use_window, dtw_type=\"shape\")\ndef discriminative_guided_warp(x, labels, batch_size=6, slope_constraint=\"symmetric\", use_window=True, dtw_type=\"normal\", use_variable_slice=True, verbose=0):\n    # use verbose = -1 to turn off warnings\n    # slope_constraint is for DTW. \"symmetric\" or \"asymmetric\"\n    # dtw_type is for shapeDTW or DTW. \"normal\" or \"shape\"\n    import utils.dtw as dtw\n    if use_window:\n        window = np.ceil(x.shape[1] / 10.).astype(int)\n    else:",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "discriminative_guided_warp",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def discriminative_guided_warp(x, labels, batch_size=6, slope_constraint=\"symmetric\", use_window=True, dtw_type=\"normal\", use_variable_slice=True, verbose=0):\n    # use verbose = -1 to turn off warnings\n    # slope_constraint is for DTW. \"symmetric\" or \"asymmetric\"\n    # dtw_type is for shapeDTW or DTW. \"normal\" or \"shape\"\n    import utils.dtw as dtw\n    if use_window:\n        window = np.ceil(x.shape[1] / 10.).astype(int)\n    else:\n        window = None\n    orig_steps = np.arange(x.shape[1])",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "discriminative_guided_warp_shape",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def discriminative_guided_warp_shape(x, labels, batch_size=6, slope_constraint=\"symmetric\", use_window=True):\n    return discriminative_guided_warp(x, labels, batch_size, slope_constraint, use_window, dtw_type=\"shape\")\ndef run_augmentation(x, y, args):\n    print(\"Augmenting %s\"%args.data)\n    np.random.seed(args.seed)\n    x_aug = x\n    y_aug = y\n    if args.augmentation_ratio > 0:\n        augmentation_tags = \"%d\"%args.augmentation_ratio\n        for n in range(args.augmentation_ratio):",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "run_augmentation",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def run_augmentation(x, y, args):\n    print(\"Augmenting %s\"%args.data)\n    np.random.seed(args.seed)\n    x_aug = x\n    y_aug = y\n    if args.augmentation_ratio > 0:\n        augmentation_tags = \"%d\"%args.augmentation_ratio\n        for n in range(args.augmentation_ratio):\n            x_temp, augmentation_tags = augment(x, y, args)\n            x_aug = np.append(x_aug, x_temp, axis=0)",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "run_augmentation_single",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def run_augmentation_single(x, y, args):\n    # print(\"Augmenting %s\"%args.data)\n    np.random.seed(args.seed)\n    x_aug = x\n    y_aug = y\n    if args.augmentation_ratio > 0:\n        augmentation_tags = \"%d\"%args.augmentation_ratio\n        for n in range(args.augmentation_ratio):\n            x_temp, augmentation_tags = augment(x, y, args)\n            x_aug =x_temp",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "augment",
        "kind": 2,
        "importPath": "utils.augmentation",
        "description": "utils.augmentation",
        "peekOfCode": "def augment(x, y, args):\n    import utils.augmentation as aug\n    augmentation_tags = \"\"\n    if args.jitter:\n        x = aug.jitter(x)\n        augmentation_tags += \"_jitter\"\n    if args.scaling:\n        x = aug.scaling(x)\n        augmentation_tags += \"_scaling\"\n    if args.rotation:",
        "detail": "utils.augmentation",
        "documentation": {}
    },
    {
        "label": "dtw",
        "kind": 2,
        "importPath": "utils.dtw",
        "description": "utils.dtw",
        "peekOfCode": "def dtw(prototype, sample, return_flag = RETURN_VALUE, slope_constraint=\"asymmetric\", window=None):\n    \"\"\" Computes the DTW of two sequences.\n    :param prototype: np array [0..b]\n    :param sample: np array [0..t]\n    :param extended: bool\n    \"\"\"\n    p = prototype.shape[0]\n    assert p != 0, \"Prototype empty!\"\n    s = sample.shape[0]\n    assert s != 0, \"Sample empty!\"",
        "detail": "utils.dtw",
        "documentation": {}
    },
    {
        "label": "shape_dtw",
        "kind": 2,
        "importPath": "utils.dtw",
        "description": "utils.dtw",
        "peekOfCode": "def shape_dtw(prototype, sample, return_flag = RETURN_VALUE, slope_constraint=\"asymmetric\", window=None, descr_ratio=0.05):\n    \"\"\" Computes the shapeDTW of two sequences.\n    :param prototype: np array [0..b]\n    :param sample: np array [0..t]\n    :param extended: bool\n    \"\"\"\n    # shapeDTW\n    # https://www.sciencedirect.com/science/article/pii/S0031320317303710\n    p = prototype.shape[0]\n    assert p != 0, \"Prototype empty!\"",
        "detail": "utils.dtw",
        "documentation": {}
    },
    {
        "label": "draw_graph2d",
        "kind": 2,
        "importPath": "utils.dtw",
        "description": "utils.dtw",
        "peekOfCode": "def draw_graph2d(cost, DTW, path, prototype, sample):\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(12, 8))\n   # plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05, hspace=.01)\n    #cost\n    plt.subplot(2, 3, 1)\n    plt.imshow(cost.T, cmap=plt.cm.gray, interpolation='none', origin='lower')\n    plt.plot(path[0], path[1], 'y')\n    plt.xlim((-0.5, cost.shape[0]-0.5))\n    plt.ylim((-0.5, cost.shape[0]-0.5))",
        "detail": "utils.dtw",
        "documentation": {}
    },
    {
        "label": "draw_graph1d",
        "kind": 2,
        "importPath": "utils.dtw",
        "description": "utils.dtw",
        "peekOfCode": "def draw_graph1d(cost, DTW, path, prototype, sample):\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(12, 8))\n   # plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05, hspace=.01)\n    p_steps = np.arange(prototype.shape[0])\n    s_steps = np.arange(sample.shape[0])\n    #cost\n    plt.subplot(2, 3, 1)\n    plt.imshow(cost.T, cmap=plt.cm.gray, interpolation='none', origin='lower')\n    plt.plot(path[0], path[1], 'y')",
        "detail": "utils.dtw",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "utils.dtw",
        "description": "utils.dtw",
        "peekOfCode": "__author__ = 'Brian Iwana'\nimport numpy as np\nimport math\nimport sys\nRETURN_VALUE = 0\nRETURN_PATH = 1\nRETURN_ALL = -1\n# Core DTW\ndef _traceback(DTW, slope_constraint):\n    i, j = np.array(DTW.shape) - 1",
        "detail": "utils.dtw",
        "documentation": {}
    },
    {
        "label": "RETURN_VALUE",
        "kind": 5,
        "importPath": "utils.dtw",
        "description": "utils.dtw",
        "peekOfCode": "RETURN_VALUE = 0\nRETURN_PATH = 1\nRETURN_ALL = -1\n# Core DTW\ndef _traceback(DTW, slope_constraint):\n    i, j = np.array(DTW.shape) - 1\n    p, q = [i-1], [j-1]\n    if slope_constraint == \"asymmetric\":\n        while (i > 1):\n            tb = np.argmin((DTW[i-1, j], DTW[i-1, j-1], DTW[i-1, j-2]))",
        "detail": "utils.dtw",
        "documentation": {}
    },
    {
        "label": "RETURN_PATH",
        "kind": 5,
        "importPath": "utils.dtw",
        "description": "utils.dtw",
        "peekOfCode": "RETURN_PATH = 1\nRETURN_ALL = -1\n# Core DTW\ndef _traceback(DTW, slope_constraint):\n    i, j = np.array(DTW.shape) - 1\n    p, q = [i-1], [j-1]\n    if slope_constraint == \"asymmetric\":\n        while (i > 1):\n            tb = np.argmin((DTW[i-1, j], DTW[i-1, j-1], DTW[i-1, j-2]))\n            if (tb == 0):",
        "detail": "utils.dtw",
        "documentation": {}
    },
    {
        "label": "RETURN_ALL",
        "kind": 5,
        "importPath": "utils.dtw",
        "description": "utils.dtw",
        "peekOfCode": "RETURN_ALL = -1\n# Core DTW\ndef _traceback(DTW, slope_constraint):\n    i, j = np.array(DTW.shape) - 1\n    p, q = [i-1], [j-1]\n    if slope_constraint == \"asymmetric\":\n        while (i > 1):\n            tb = np.argmin((DTW[i-1, j], DTW[i-1, j-1], DTW[i-1, j-2]))\n            if (tb == 0):\n                i = i - 1",
        "detail": "utils.dtw",
        "documentation": {}
    },
    {
        "label": "dtw",
        "kind": 2,
        "importPath": "utils.dtw_metric",
        "description": "utils.dtw_metric",
        "peekOfCode": "def dtw(x, y, dist, warp=1, w=inf, s=1.0):\n    \"\"\"\n    Computes Dynamic Time Warping (DTW) of two sequences.\n    :param array x: N1*M array\n    :param array y: N2*M array\n    :param func dist: distance used as cost measure\n    :param int warp: how many shifts are computed.\n    :param int w: window size limiting the maximal distance between indices of matched entries |i,j|.\n    :param float s: weight applied on off-diagonal moves of the path. As s gets larger, the warping path is increasingly biased towards the diagonal\n    Returns the minimum distance, the cost matrix, the accumulated cost matrix, and the wrap path.",
        "detail": "utils.dtw_metric",
        "documentation": {}
    },
    {
        "label": "accelerated_dtw",
        "kind": 2,
        "importPath": "utils.dtw_metric",
        "description": "utils.dtw_metric",
        "peekOfCode": "def accelerated_dtw(x, y, dist, warp=1):\n    \"\"\"\n    Computes Dynamic Time Warping (DTW) of two sequences in a faster way.\n    Instead of iterating through each element and calculating each distance,\n    this uses the cdist function from scipy (https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html)\n    :param array x: N1*M array\n    :param array y: N2*M array\n    :param string or func dist: distance parameter for cdist. When string is given, cdist uses optimized functions for the distance metrics.\n    If a string is passed, the distance function can be 'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'wminkowski', 'yule'.\n    :param int warp: how many shifts are computed.",
        "detail": "utils.dtw_metric",
        "documentation": {}
    },
    {
        "label": "RSE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def RSE(pred, true):\n    return np.sqrt(np.sum((true - pred) ** 2)) / np.sqrt(np.sum((true - true.mean()) ** 2))\ndef CORR(pred, true):\n    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)\n    d = np.sqrt(((true - true.mean(0)) ** 2 * (pred - pred.mean(0)) ** 2).sum(0))\n    return (u / d).mean(-1)\ndef MAE(pred, true):\n    return np.mean(np.abs(pred - true))\ndef MSE(pred, true):\n    return np.mean((pred - true) ** 2)",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "CORR",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def CORR(pred, true):\n    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)\n    d = np.sqrt(((true - true.mean(0)) ** 2 * (pred - pred.mean(0)) ** 2).sum(0))\n    return (u / d).mean(-1)\ndef MAE(pred, true):\n    return np.mean(np.abs(pred - true))\ndef MSE(pred, true):\n    return np.mean((pred - true) ** 2)\ndef RMSE(pred, true):\n    return np.sqrt(MSE(pred, true))",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "MAE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def MAE(pred, true):\n    return np.mean(np.abs(pred - true))\ndef MSE(pred, true):\n    return np.mean((pred - true) ** 2)\ndef RMSE(pred, true):\n    return np.sqrt(MSE(pred, true))\ndef MAPE(pred, true):\n    return np.mean(np.abs((pred - true) / true))\ndef MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "MSE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def MSE(pred, true):\n    return np.mean((pred - true) ** 2)\ndef RMSE(pred, true):\n    return np.sqrt(MSE(pred, true))\ndef MAPE(pred, true):\n    return np.mean(np.abs((pred - true) / true))\ndef MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))\ndef metric(pred, true):\n    mae = MAE(pred, true)",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "RMSE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def RMSE(pred, true):\n    return np.sqrt(MSE(pred, true))\ndef MAPE(pred, true):\n    return np.mean(np.abs((pred - true) / true))\ndef MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))\ndef metric(pred, true):\n    mae = MAE(pred, true)\n    mse = MSE(pred, true)\n    rmse = RMSE(pred, true)",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "MAPE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def MAPE(pred, true):\n    return np.mean(np.abs((pred - true) / true))\ndef MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))\ndef metric(pred, true):\n    mae = MAE(pred, true)\n    mse = MSE(pred, true)\n    rmse = RMSE(pred, true)\n    mape = MAPE(pred, true)\n    mspe = MSPE(pred, true)",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "MSPE",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def MSPE(pred, true):\n    return np.mean(np.square((pred - true) / true))\ndef metric(pred, true):\n    mae = MAE(pred, true)\n    mse = MSE(pred, true)\n    rmse = RMSE(pred, true)\n    mape = MAPE(pred, true)\n    mspe = MSPE(pred, true)\n    return mae, mse, rmse, mape, mspe",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "metric",
        "kind": 2,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "def metric(pred, true):\n    mae = MAE(pred, true)\n    mse = MSE(pred, true)\n    rmse = RMSE(pred, true)\n    mape = MAPE(pred, true)\n    mspe = MSPE(pred, true)\n    return mae, mse, rmse, mape, mspe",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "print_args",
        "kind": 2,
        "importPath": "utils.print_args",
        "description": "utils.print_args",
        "peekOfCode": "def print_args(args):\n    print(\"\\033[1m\" + \"Basic Config\" + \"\\033[0m\")\n    print(f'  {\"Task Name:\":<20}{args.task_name:<20}{\"Is Training:\":<20}{args.is_training:<20}')\n    print(f'  {\"Model ID:\":<20}{args.model_id:<20}{\"Model:\":<20}{args.model:<20}')\n    print()\n    print(\"\\033[1m\" + \"Data Loader\" + \"\\033[0m\")\n    print(f'  {\"Data:\":<20}{args.data:<20}{\"Root Path:\":<20}{args.root_path:<20}')\n    print(f'  {\"Data Path:\":<20}{args.data_path:<20}{\"Features:\":<20}{args.features:<20}')\n    print(f'  {\"Target:\":<20}{args.target:<20}{\"Freq:\":<20}{args.freq:<20}')\n    print(f'  {\"Checkpoints:\":<20}{args.checkpoints:<20}')",
        "detail": "utils.print_args",
        "documentation": {}
    },
    {
        "label": "TimeFeature",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class TimeFeature:\n    def __init__(self):\n        pass\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        pass\n    def __repr__(self):\n        return self.__class__.__name__ + \"()\"\nclass SecondOfMinute(TimeFeature):\n    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "SecondOfMinute",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class SecondOfMinute(TimeFeature):\n    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.second / 59.0 - 0.5\nclass MinuteOfHour(TimeFeature):\n    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.minute / 59.0 - 0.5\nclass HourOfDay(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "MinuteOfHour",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class MinuteOfHour(TimeFeature):\n    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.minute / 59.0 - 0.5\nclass HourOfDay(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.hour / 23.0 - 0.5\nclass DayOfWeek(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "HourOfDay",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class HourOfDay(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.hour / 23.0 - 0.5\nclass DayOfWeek(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.dayofweek / 6.0 - 0.5\nclass DayOfMonth(TimeFeature):\n    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "DayOfWeek",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class DayOfWeek(TimeFeature):\n    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return index.dayofweek / 6.0 - 0.5\nclass DayOfMonth(TimeFeature):\n    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.day - 1) / 30.0 - 0.5\nclass DayOfYear(TimeFeature):\n    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "DayOfMonth",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class DayOfMonth(TimeFeature):\n    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.day - 1) / 30.0 - 0.5\nclass DayOfYear(TimeFeature):\n    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.dayofyear - 1) / 365.0 - 0.5\nclass MonthOfYear(TimeFeature):\n    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "DayOfYear",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class DayOfYear(TimeFeature):\n    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.dayofyear - 1) / 365.0 - 0.5\nclass MonthOfYear(TimeFeature):\n    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.month - 1) / 11.0 - 0.5\nclass WeekOfYear(TimeFeature):\n    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "MonthOfYear",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class MonthOfYear(TimeFeature):\n    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.month - 1) / 11.0 - 0.5\nclass WeekOfYear(TimeFeature):\n    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.isocalendar().week - 1) / 52.0 - 0.5\ndef time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n    \"\"\"",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "WeekOfYear",
        "kind": 6,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "class WeekOfYear(TimeFeature):\n    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n        return (index.isocalendar().week - 1) / 52.0 - 0.5\ndef time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n    \"\"\"\n    Returns a list of time features that will be appropriate for the given frequency string.\n    Parameters\n    ----------\n    freq_str",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "time_features_from_frequency_str",
        "kind": 2,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n    \"\"\"\n    Returns a list of time features that will be appropriate for the given frequency string.\n    Parameters\n    ----------\n    freq_str\n        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n    \"\"\"\n    features_by_offsets = {\n        offsets.YearEnd: [],",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "time_features",
        "kind": 2,
        "importPath": "utils.timefeatures",
        "description": "utils.timefeatures",
        "peekOfCode": "def time_features(dates, freq='h'):\n    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])",
        "detail": "utils.timefeatures",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "kind": 6,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "class EarlyStopping:\n    def __init__(self, patience=7, verbose=False, delta=0):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n    def __call__(self, val_loss, model, path):",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "dotdict",
        "kind": 6,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "class dotdict(dict):\n    \"\"\"dot.notation access to dictionary attributes\"\"\"\n    __getattr__ = dict.get\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\nclass StandardScaler():\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n    def transform(self, data):",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "kind": 6,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "class StandardScaler():\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n    def transform(self, data):\n        return (data - self.mean) / self.std\n    def inverse_transform(self, data):\n        return (data * self.std) + self.mean\ndef visual(true, preds=None, name='./pic/test.pdf'):\n    \"\"\"",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "adjust_learning_rate",
        "kind": 2,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "def adjust_learning_rate(optimizer, epoch, args):\n    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n    if args.lradj == 'type1':\n        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n    elif args.lradj == 'type2':\n        lr_adjust = {\n            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n            10: 5e-7, 15: 1e-7, 20: 5e-8\n        }\n    elif args.lradj == \"cosine\":",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "visual",
        "kind": 2,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "def visual(true, preds=None, name='./pic/test.pdf'):\n    \"\"\"\n    Results visualization\n    \"\"\"\n    plt.figure()\n    plt.plot(true, label='GroundTruth', linewidth=2)\n    if preds is not None:\n        plt.plot(preds, label='Prediction', linewidth=2)\n    plt.legend()\n    plt.savefig(name, bbox_inches='tight')",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "adjustment",
        "kind": 2,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "def adjustment(gt, pred):\n    anomaly_state = False\n    for i in range(len(gt)):\n        if gt[i] == 1 and pred[i] == 1 and not anomaly_state:\n            anomaly_state = True\n            for j in range(i, 0, -1):\n                if gt[j] == 0:\n                    break\n                else:\n                    if pred[j] == 0:",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "cal_accuracy",
        "kind": 2,
        "importPath": "utils.tools",
        "description": "utils.tools",
        "peekOfCode": "def cal_accuracy(y_pred, y_true):\n    return np.mean(y_pred == y_true)",
        "detail": "utils.tools",
        "documentation": {}
    },
    {
        "label": "PositionalEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class PositionalEmbedding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEmbedding, self).__init__()\n        # Compute the positional encodings once in log space.\n        pe = torch.zeros(max_len, d_model).float()\n        pe.require_grad = False\n        position = torch.arange(0, max_len).float().unsqueeze(1)\n        div_term = (torch.arange(0, d_model, 2).float()\n                    * -(math.log(10000.0) / d_model)).exp()\n        pe[:, 0::2] = torch.sin(position * div_term)",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "TokenEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class TokenEmbedding(nn.Module):\n    def __init__(self, c_in, d_model):\n        super(TokenEmbedding, self).__init__()\n        padding = 1 if torch.__version__ >= '1.5.0' else 2\n        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n        for m in self.modules():\n            if isinstance(m, nn.Conv1d):\n                nn.init.kaiming_normal_(\n                    m.weight, mode='fan_in', nonlinearity='leaky_relu')",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "FixedEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class FixedEmbedding(nn.Module):\n    def __init__(self, c_in, d_model):\n        super(FixedEmbedding, self).__init__()\n        w = torch.zeros(c_in, d_model).float()\n        w.require_grad = False\n        position = torch.arange(0, c_in).float().unsqueeze(1)\n        div_term = (torch.arange(0, d_model, 2).float()\n                    * -(math.log(10000.0) / d_model)).exp()\n        w[:, 0::2] = torch.sin(position * div_term)\n        w[:, 1::2] = torch.cos(position * div_term)",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "TemporalEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class TemporalEmbedding(nn.Module):\n    def __init__(self, d_model, embed_type='fixed', freq='h'):\n        super(TemporalEmbedding, self).__init__()\n        minute_size = 4\n        hour_size = 24\n        weekday_size = 7\n        day_size = 32\n        month_size = 13\n        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n        if freq == 't':",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "TimeFeatureEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class TimeFeatureEmbedding(nn.Module):\n    def __init__(self, d_model, embed_type='timeF', freq='h'):\n        super(TimeFeatureEmbedding, self).__init__()\n        freq_map = {'h': 4, 't': 5, 's': 6,\n                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n        d_inp = freq_map[freq]\n        self.embed = nn.Linear(d_inp, d_model, bias=False)\n    def forward(self, x):\n        return self.embed(x)\nclass DataEmbedding(nn.Module):",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "DataEmbedding",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class DataEmbedding(nn.Module):\n    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n        super(DataEmbedding, self).__init__()\n        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n        self.position_embedding = PositionalEmbedding(d_model=d_model)\n        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n            d_model=d_model, embed_type=embed_type, freq=freq)\n        self.dropout = nn.Dropout(p=dropout)\n    def forward(self, x, x_mark):",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "moving_avg",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class moving_avg(nn.Module):\n    \"\"\"\n    Moving average block to highlight the trend of time series\n    \"\"\"\n    def __init__(self, kernel_size, stride):\n        super(moving_avg, self).__init__()\n        self.kernel_size = kernel_size\n        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n    def forward(self, x):\n        # padding on the both ends of time series",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "series_decomp",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class series_decomp(nn.Module):\n    \"\"\"\n    Series decomposition block\n    \"\"\"\n    def __init__(self, kernel_size):\n        super(series_decomp, self).__init__()\n        self.moving_avg = moving_avg(kernel_size, stride=1)\n    def forward(self, x):\n        moving_mean = self.moving_avg(x)\n        res = x - moving_mean",
        "detail": "layers",
        "documentation": {}
    },
    {
        "label": "series_decomp_multi",
        "kind": 6,
        "importPath": "layers",
        "description": "layers",
        "peekOfCode": "class series_decomp_multi(nn.Module):\n    \"\"\"\n    Multiple Series decomposition block from FEDformer\n    \"\"\"\n    def __init__(self, kernel_size):\n        super(series_decomp_multi, self).__init__()\n        self.kernel_size = kernel_size\n        self.series_decomp = [series_decomp(kernel) for kernel in kernel_size]\n    def forward(self, x):\n        moving_mean = []",
        "detail": "layers",
        "documentation": {}
    }
]